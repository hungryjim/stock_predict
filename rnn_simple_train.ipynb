{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_simple_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQbpI1o1nPS-",
        "colab_type": "text"
      },
      "source": [
        "# **import all the libs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkJ7ieC-xWAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get all the imports\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from pandas import concat, DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, LSTM, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "from prepare_data_for_modal import prepare_data, series_to_supervised, split_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beOOGUK9nRBx",
        "colab_type": "text"
      },
      "source": [
        "# **get the train_x  train_y, test_x test_y, and define the model structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1_Kcc0puTqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_base(stock_num):\n",
        "    pre_stock_data, stock, news = prepare_data(stock_num)\n",
        "\n",
        "    # Polymerise Stock data¶\n",
        "    # since we are using only one data coloumn form stock\n",
        "    # # to make polynomial feature set\n",
        "    poly = PolynomialFeatures(degree=2)\n",
        "    stock = poly.fit_transform(stock)\n",
        "\n",
        "    # Split the data into train and test data¶\n",
        "    train_x = np.hstack([stock[:407], news[:407]])\n",
        "    train_x = split_sequence(train_x, 7)\n",
        "    # y就是要被预测的价格\n",
        "    train_y = pre_stock_data.iloc[1:407, 9:].values\n",
        "    train_y = series_to_supervised(train_y, 6, 1)\n",
        "\n",
        "    test_x = np.hstack([stock[393:], news[393:]])\n",
        "    test_x = split_sequence(test_x, 7)\n",
        "\n",
        "    test_y = pre_stock_data.iloc[400:, 9:].values\n",
        "\n",
        "    # reshape the data acording to the lstm\n",
        "    train_x = train_x.reshape(-1, 7, 7)\n",
        "    test_x = test_x.reshape(-1, 7, 7)\n",
        "    # train_x = np.hstack([stock[:400], news[:400]])\n",
        "    # # train_x = split_sequence(train_x, 7)\n",
        "    # # y就是要被预测的价格\n",
        "    # train_y = pre_stock_data.iloc[1:407, 9:].values\n",
        "    # train_y = series_to_supervised(train_y, 6, 1)\n",
        "\n",
        "    # test_x = np.hstack([stock[400:], news[400:]])\n",
        "    # # test_x = split_sequence(test_x, 7)\n",
        "\n",
        "    # test_y = pre_stock_data.iloc[400:, 9:].values\n",
        "\n",
        "    # # reshape the data acording to the lstm\n",
        "    # train_x = train_x.reshape(-1, 1, 7)\n",
        "    # test_x = test_x.reshape(-1, 1, 7)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    # Made on the basis of assumption made on data analysis\n",
        "    # make model\n",
        "    model = Sequential()\n",
        "    # layer 1\n",
        "    model.add(LSTM(128, input_shape=(7, train_x.shape[2:][0]), activation='relu', return_sequences=True))\n",
        "    model.add(Dropout(0.2))  # \n",
        "    model.add(BatchNormalization())\n",
        "    # layer 2\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    # layer 3\n",
        "    model.add(LSTM(128, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    # layer 4\n",
        "    model.add(Dense(200, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(BatchNormalization())\n",
        "    # layer 5\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    # layer 6\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    # final output in 1\n",
        "    model.add(Dense(7))\n",
        "    # make optimiser\n",
        "    opt=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.0)\n",
        "    # compile the model\n",
        "    model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "    # to log the data for tensorboard\n",
        "    time = datetime.now()\n",
        "    tbCallBack = keras.callbacks.TensorBoard(log_dir='./log/stock_'+stock_num+'_baseline' + str(time), write_graph=True)\n",
        "\n",
        "    # for the model checkpoints\n",
        "    filepath = './log/stock'+stock_num+'_baseline_weights.best.hdf5'\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "    callbacks_list = [checkpoint, tbCallBack]\n",
        "    model.summary()\n",
        "    return model, callbacks_list, train_x, train_y, pre_stock_data, test_x, test_y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1J_WwzJnUUa",
        "colab_type": "text"
      },
      "source": [
        "# **train the model and show the results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LAYNERaxnVO",
        "colab_type": "code",
        "outputId": "62ca977a-2356-4b7f-b7c3-05627c40759d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        }
      },
      "source": [
        "def Simple_train_model(stock_num):\n",
        "    model, callbacks_list, train_x, train_y, pre_stock_data, test_x, test_y = model_base(stock_num)\n",
        "    model.fit(\n",
        "        train_x\n",
        "        , train_y\n",
        "        , epochs=80\n",
        "        , batch_size=10\n",
        "        , verbose=1\n",
        "        , validation_split=0.1\n",
        "        , callbacks=callbacks_list\n",
        "    )\n",
        "\n",
        "    predict=model.predict(test_x)\n",
        "\n",
        "    #Plot the data that is predicted by modelc\n",
        "    #matplotlib inline\n",
        "    fig = plt.figure(figsize=(15, 8), dpi=80, facecolor='w', edgecolor='k')\n",
        "    # index = pd.date_range(start = pre_stock_data['Date'][0], end = pre_stock_data['Date'][406], freq = \"D\")\n",
        "    predict_Date = ['2015/12/21', '2015/12/22', '2015/12/23', '2015/12/24', '2015/12/28', '2015/12/29', '2015/12/30']\n",
        "    dataArr = np.append(pre_stock_data['Date'], predict_Date)\n",
        "    index = [pd.to_datetime(date, format='%Y-%m-%d').date() for date in dataArr]\n",
        "    predata = np.squeeze(predict[:, :1], axis=1)[0:-6]\n",
        "    day1 = np.squeeze(predict[:, :1], axis=1)[-1]\n",
        "    day2 = np.squeeze(predict[:, 1:2], axis=1)[-1]\n",
        "    day3 = np.squeeze(predict[:1, 2:3], axis=1)[-1]\n",
        "    day4 = np.squeeze(predict[:1, 3:4], axis=1)[-1]\n",
        "    day5 = np.squeeze(predict[:1, 4:5], axis=1)[-1]\n",
        "    day6 = np.squeeze(predict[:1, 5:6], axis=1)[-1]\n",
        "    day7 = np.squeeze(predict[:1, 6:7], axis=1)[-1]\n",
        "    predict_arr = np.round(np.array([day1, day2, day3, day4, day5, day6, day7]), 1)\n",
        "    print('predict_seven_days == ', predict_arr)\n",
        "    ax1 = fig.add_subplot(2, 1, 1)\n",
        "    ax2 = fig.add_subplot(2, 1, 2)\n",
        "    ax1.plot(index[400:496], np.squeeze(test_y, axis=1), label='test_y')\n",
        "    ax1.plot(index[406:496], np.squeeze(predata), label='predict_stock#'+stock_num)\n",
        "    ax1.plot(index[496:503], np.squeeze(predict_arr), label='predict_stock#'+stock_num+'_seven_days')\n",
        "    score = (abs(np.squeeze(test_y, axis=1) - np.squeeze(predict[:, 6:7], axis=1)) / np.squeeze(test_y, axis=1)).sum()\n",
        "    ax1.set_title('the score of this model is:'+ str(score))\n",
        "    train_y_show = pre_stock_data.iloc[1:407, 9:].values\n",
        "    ax2.set_title('Prediction of the model on the training data to see that if its overfitting or not.')\n",
        "    ax2.plot(index[:406], np.round(np.squeeze(train_y_show, axis=1), 1), label='test_y')\n",
        "    ax2.plot(index[:400], np.round(np.squeeze(model.predict(train_x)[:, :1], axis=1), 1), label='predict_test')\n",
        "    ax1.legend()\n",
        "    ax2.legend()\n",
        "    plt.show()\n",
        "Simple_train_model('2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/prepare_data_for_modal.py:68: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  pre_stock1_data['Month'][i] = int(pre_stock1_data['Date'][i].split('/')[1])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_156 (LSTM)              (None, 7, 128)            69632     \n",
            "_________________________________________________________________\n",
            "dropout_306 (Dropout)        (None, 7, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_306 (Bat (None, 7, 128)            512       \n",
            "_________________________________________________________________\n",
            "lstm_157 (LSTM)              (None, 7, 128)            131584    \n",
            "_________________________________________________________________\n",
            "dropout_307 (Dropout)        (None, 7, 128)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_307 (Bat (None, 7, 128)            512       \n",
            "_________________________________________________________________\n",
            "lstm_158 (LSTM)              (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_308 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_308 (Bat (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_201 (Dense)            (None, 200)               25800     \n",
            "_________________________________________________________________\n",
            "dropout_309 (Dropout)        (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_309 (Bat (None, 200)               800       \n",
            "_________________________________________________________________\n",
            "dense_202 (Dense)            (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "dropout_310 (Dropout)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_310 (Bat (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_203 (Dense)            (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_311 (Dropout)        (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_311 (Bat (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_204 (Dense)            (None, 7)                 357       \n",
            "=================================================================\n",
            "Total params: 387,043\n",
            "Trainable params: 385,575\n",
            "Non-trainable params: 1,468\n",
            "_________________________________________________________________\n",
            "Train on 360 samples, validate on 40 samples\n",
            "Epoch 1/80\n",
            "360/360 [==============================] - 17s 47ms/step - loss: 121630.7884 - acc: 0.1250 - val_loss: 219382.8594 - val_acc: 0.1250\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 219382.85938, saving model to ./log/stock2_baseline_weights.best.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjNLYl-C48hq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}